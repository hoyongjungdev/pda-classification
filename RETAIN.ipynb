{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RETAIN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOQDLum25+axl3/Py3OvTmS"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cyIMrD3gpC3"
      },
      "source": [
        "https://github.com/ast0414/pytorch-retain\n",
        "\n",
        "\n",
        "https://github.com/easyfan327/Pytorch-RETAIN\n",
        "\n",
        "\n",
        "https://proceedings.neurips.cc/paper/2016/file/231141b34c82aa95e48810a9d1b33a79-Paper.pdf\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOJLXF4Z1VhU"
      },
      "source": [
        "# module import\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import TensorDataset\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import pickle as pickle\n",
        "import random\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N601DUqFfcer"
      },
      "source": [
        "class RetainNN(nn.Module):\n",
        "    def __init__(self, params: dict):\n",
        "        # params : info of all parameters\n",
        "        super(RetainNN, self).__init__()\n",
        "\n",
        "        \"\"\"\n",
        "        num_embeddings(int): embedding 전 size\n",
        "        embedding_dim(int): embedding 후 size\n",
        "        \"\"\"\n",
        "        self.emb_layer = nn.Linear(in_features=params[\"num_embeddings\"], out_features=params[\"embedding_dim\"])\n",
        "        self.dropout = nn.Dropout(params[\"dropout_p\"])\n",
        "\n",
        "        # attention\n",
        "        self.variable_level_rnn = nn.GRU(params[\"var_rnn_hidden_size\"], params[\"var_rnn_output_size\"])\n",
        "        self.visit_level_rnn = nn.GRU(params[\"visit_rnn_hidden_size\"], params[\"visit_rnn_output_size\"])\n",
        "        self.variable_level_attention = nn.Linear(params[\"var_rnn_output_size\"], params[\"var_attn_output_size\"]) # β (vector)\n",
        "        self.visit_level_attention = nn.Linear(params[\"visit_rnn_output_size\"], params[\"visit_attn_output_size\"]) # α (scalar)\n",
        "\n",
        "        self.output_dropout = nn.Dropout(params[\"output_dropout_p\"])\n",
        "        self.output_layer = nn.Linear(params[\"embedding_output_size\"], params[\"num_class\"])\n",
        "\n",
        "        self.var_hidden_size = params[\"var_rnn_hidden_size\"]\n",
        "        self.visit_hidden_size = params[\"visit_rnn_hidden_size\"]\n",
        "\n",
        "        self.n_samples = params[\"batch_size\"]\n",
        "        self.reverse_rnn_feeding = params[\"reverse_rnn_feeding\"]\n",
        "\n",
        "\n",
        "    def forward(self, input, var_rnn_hidden, visit_rnn_hidden):\n",
        "        \"\"\"\n",
        "        input: \n",
        "        var_rnn_hidden:\n",
        "        visit_rnn_hidden:\n",
        "        return:\n",
        "        \"\"\"\n",
        "        # emb_layer: input(*): LongTensor of arbitrary shape containing the indices to extract\n",
        "        # emb_layer: output(*,H): where * is the input shape and H = embedding_dim\n",
        "        # print(\"size of input:\",end=' ')\n",
        "        # print(input.shape)\n",
        "        v = self.emb_layer(input)\n",
        "        # print(\"size of v:\",end=' ')\n",
        "        # print(v.shape)\n",
        "        v = self.dropout(v)\n",
        "\n",
        "        # GRU input : (seq_len, batch, input_size)\n",
        "        # seq_len: visit_seq_len\n",
        "        # batch: batch_size\n",
        "        # input_size: embedding dimension\n",
        "\n",
        "        # h_0 of shape (num_layers*num_directions, batch, hidden_size)\n",
        "        # num_layers(1)*num_directions(1)\n",
        "        # batch: batch_size\n",
        "        # hidden_size: hidden layer dimension\n",
        "\n",
        "        if self.reverse_rnn_feeding:\n",
        "            # torch.flip : reverse order\n",
        "            visit_rnn_output, visit_rnn_hidden = self.visit_level_rnn(torch.flip(v, [0]), visit_rnn_hidden)\n",
        "            alpha = self.visit_level_attention(torch.flip(visit_rnn_output, [0])) # scalar\n",
        "        else:\n",
        "            visit_rnn_output, visit_rnn_hidden = self.visit_level_rnn(v, visit_rnn_hidden)\n",
        "            alpha = self.visit_level_attention(visit_rnn_output)\n",
        "        visit_attn_w = F.softmax(alpha, dim=0)\n",
        "\n",
        "        if self.reverse_rnn_feeding:\n",
        "            var_rnn_output, var_rnn_hidden = self.variable_level_rnn(torch.flip(v, [0]), var_rnn_hidden)\n",
        "            beta = self.variable_level_attention(torch.flip(var_rnn_output, [0]))\n",
        "        else:\n",
        "            var_rnn_output, var_rnn_hidden = self.variable_level_rnn(v, var_rnn_hidden)\n",
        "            beta = self.variable_level_attention(var_rnn_output) # vector\n",
        "        var_attn_w = torch.tanh(beta)\n",
        "\n",
        "        # print(\"beta attn:\",end=' ')\n",
        "        # print(var_attn_w.shape)\n",
        "        # '*' = hadamard product (element-wise product)\n",
        "        attn_w = visit_attn_w * var_attn_w\n",
        "        c = torch.sum(attn_w * v, dim=0)\n",
        "        # print(\"context:\",end=' ')\n",
        "        # print(c.shape)\n",
        "\n",
        "        c = self.output_dropout(c)\n",
        "        #print(\"context:\",end=' ')\n",
        "        #print(c.shape)\n",
        "        output = self.output_layer(c)\n",
        "        #print(\"output:\")\n",
        "        #print(output.shape)\n",
        "        output = F.softmax(output, dim=1)\n",
        "        # print(\"output:\",end=' ')\n",
        "        # print(output.shape)\n",
        "\n",
        "        return output, var_rnn_hidden, visit_rnn_hidden\n",
        "\n",
        "    def init_hidden(self, current_batch_size):\n",
        "        return torch.zeros(current_batch_size, self.var_hidden_size).unsqueeze(0).to(device), torch.zeros(current_batch_size, self.visit_hidden_size).unsqueeze(0).to(device)\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgBmN4YJflMO"
      },
      "source": [
        "\"\"\"\n",
        "RETAIN 모델 설계에 필요한 parameter\n",
        "data에 따라 달라짐\n",
        "\"\"\"\n",
        "def init_params(params: dict):\n",
        "    # embedding matrix\n",
        "    params[\"num_embeddings\"] = 942\n",
        "    params[\"embedding_dim\"] = 128\n",
        "    # embedding dropout\n",
        "    params[\"dropout_p\"] = 0.5\n",
        "    # Alpha (scalar)\n",
        "    params[\"visit_rnn_hidden_size\"] = 128\n",
        "    params[\"visit_rnn_output_size\"] = 128\n",
        "    params[\"visit_attn_output_size\"] = 1\n",
        "    # Beta (vector)\n",
        "    params[\"var_rnn_hidden_size\"] = 128\n",
        "    params[\"var_rnn_output_size\"] = 128\n",
        "    params[\"var_attn_output_size\"] = 128\n",
        "\n",
        "    params[\"embedding_output_size\"] = 128\n",
        "    params[\"num_class\"] = 2 # 0 or 1\n",
        "    params[\"output_dropout_p\"] = 0.8\n",
        "\n",
        "    params[\"batch_size\"] = 100\n",
        "    params[\"n_epoches\"] = 100\n",
        "\n",
        "    params[\"test_ratio\"] = 0.2\n",
        "    params[\"validation_ratio\"] = 0.1\n",
        "    # params[\"sequence_file\"] = \"\"\n",
        "    # params[\"label_file\"] = \"\"\n",
        "\n",
        "    params[\"reverse_rnn_feeding\"] = True\n",
        "\n",
        "\n",
        "# padding\n",
        "def padMatrixWithoutTime(seqs, options):\n",
        "    lengths = np.array([len(seq) for seq in seqs]).astype('int32')\n",
        "    n_samples = len(seqs)\n",
        "    maxlen = np.max(lengths)\n",
        "\n",
        "    x = np.zeros((maxlen, n_samples, options['num_embeddings']))\n",
        "    for idx, seq in enumerate(seqs):\n",
        "        for xvec, subseq in zip(x[:, idx, :], seq):\n",
        "            # 1로 padding\n",
        "            xvec[subseq] = 1.\n",
        "    return x, lengths\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "data loading (sample에서 pickle을 썼는데 np.load해도 됩니다)\n",
        "\"\"\"\n",
        "def init_data(params: dict):\n",
        "    sequences = np.array(pickle.load(open(params[\"sequence_file\"], 'rb')))\n",
        "    labels = np.array(pickle.load(open(params[\"label_file\"], 'rb')))\n",
        "\n",
        "    data_size = len(labels)\n",
        "    ind = np.random.permutation(data_size)\n",
        "\n",
        "    test_size = int(params[\"test_ratio\"] * data_size)\n",
        "    validation_size = int(params[\"validation_ratio\"] * data_size)\n",
        "\n",
        "    test_indices = ind[:test_size]\n",
        "    valid_indices = ind[test_size:test_size + validation_size]\n",
        "    train_indices = ind[test_size + validation_size:]\n",
        "\n",
        "    train_set_x = sequences[train_indices]\n",
        "    train_set_y = labels[train_indices]\n",
        "    test_set_x = sequences[test_indices]\n",
        "    test_set_y = labels[test_indices]\n",
        "    valid_set_x = sequences[valid_indices]\n",
        "    valid_set_y = labels[valid_indices]\n",
        "\n",
        "    def len_argsort(seq):\n",
        "        return sorted(range(len(seq)), key=lambda x: len(seq[x]))\n",
        "\n",
        "    train_sorted_index = len_argsort(train_set_x)\n",
        "    train_set_x = [train_set_x[i] for i in train_sorted_index]\n",
        "    train_set_y = [train_set_y[i] for i in train_sorted_index]\n",
        "\n",
        "    valid_sorted_index = len_argsort(valid_set_x)\n",
        "    valid_set_x = [valid_set_x[i] for i in valid_sorted_index]\n",
        "    valid_set_y = [valid_set_y[i] for i in valid_sorted_index]\n",
        "\n",
        "    test_sorted_index = len_argsort(test_set_x)\n",
        "    test_set_x = [test_set_x[i] for i in test_sorted_index]\n",
        "    test_set_y = [test_set_y[i] for i in test_sorted_index]\n",
        "\n",
        "    return train_set_x, train_set_y, valid_set_x, valid_set_y, test_set_x, test_set_y\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ihywYJUfqKc"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(device)\n",
        "\n",
        "    parameters = dict()\n",
        "    init_params(parameters)\n",
        "\n",
        "    train_set_x, train_set_y, valid_set_x, valid_set_y, test_set_x, test_set_y = init_data(parameters)\n",
        "\n",
        "    model = RetainNN(params=parameters).to(device)\n",
        "    optimizer = torch.optim.Adadelta(model.parameters(), lr=0.1, rho=0.9, eps=1e-6, weight_decay=0.001)\n",
        "    loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    n_batches = int(np.ceil(float(len(train_set_y)) / float(parameters[\"batch_size\"])))\n",
        "    best_valid_auc = 0\n",
        "    best_test_auc = 0\n",
        "    best_epoch = 0\n",
        "    for epoch in range(parameters[\"n_epoches\"]):\n",
        "        model.train()\n",
        "        loss_vector = torch.zeros(n_batches, dtype=torch.float)\n",
        "        for index in random.sample(range(n_batches), n_batches):\n",
        "            xb = train_set_x[index*parameters[\"batch_size\"]:(index+1)*parameters[\"batch_size\"]]\n",
        "            yb = train_set_y[index*parameters[\"batch_size\"]:(index+1)*parameters[\"batch_size\"]]\n",
        "            xbpad, xbpad_lengths = padMatrixWithoutTime(seqs=xb, options=parameters)\n",
        "            # memory 상속받아 tensor로 전환\n",
        "            xbpadtensor = torch.from_numpy(xbpad).float().to(device)\n",
        "            ybtensor = torch.from_numpy(np.array(yb)).long().to(device)\n",
        "            #print(xbpadtensor.shape)\n",
        "            var_rnn_hidden_init, visit_rnn_hidden_init = model.init_hidden(xbpadtensor.shape[1])\n",
        "\n",
        "            # forwarding\n",
        "            pred, var_rnn_hidden_init, visit_rnn_hidden_init = model(xbpadtensor, var_rnn_hidden_init, visit_rnn_hidden_init)\n",
        "            pred = pred.squeeze(1)\n",
        "            # print(\"pred:\",end=' ')\n",
        "            # print(pred.shape, pred.data, sep=', ')\n",
        "            # print(\"ybtensor:\",end=' ')\n",
        "            # print(ybtensor.shape)\n",
        "\n",
        "            loss = loss_fn(pred, ybtensor)\n",
        "            loss.backward()\n",
        "            loss_vector[index] = loss\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        model.eval()\n",
        "        # valid\n",
        "        x, x_length = padMatrixWithoutTime(seqs=valid_set_x, options=parameters)\n",
        "        x = torch.from_numpy(x).float().to(device)\n",
        "        y_true = torch.from_numpy(np.array(valid_set_y)).long().to(device)\n",
        "        var_rnn_hidden_init, visit_rnn_hidden_init = model.init_hidden(x.shape[1])\n",
        "        y_hat, var_rnn_hidden_init, visit_rnn_hidden_init = model(x, var_rnn_hidden_init, visit_rnn_hidden_init)\n",
        "        y_true = y_true.unsqueeze(1)\n",
        "        y_true_oh = torch.zeros(y_hat.shape).to(device).scatter_(1, y_true, 1)\n",
        "        auc = roc_auc_score(y_true=y_true_oh.detach().cpu().numpy(), y_score=y_hat.detach().cpu().numpy())\n",
        "        \n",
        "        # test\n",
        "        x, x_length = padMatrixWithoutTime(seqs=test_set_x, options=parameters)\n",
        "        x = torch.from_numpy(x).float().to(device)\n",
        "        y_true = torch.from_numpy(np.array(test_set_y)).long().to(device)\n",
        "        var_rnn_hidden_init, visit_rnn_hidden_init = model.init_hidden(x.shape[1])\n",
        "        y_hat, var_rnn_hidden_init, visit_rnn_hidden_init = model(x, var_rnn_hidden_init, visit_rnn_hidden_init)\n",
        "        y_true = y_true.unsqueeze(1)\n",
        "        y_true_oh = torch.zeros(y_hat.shape).to(device).scatter_(1, y_true, 1)\n",
        "        test_auc = roc_auc_score(y_true=y_true_oh.detach().cpu().numpy(), y_score=y_hat.detach().cpu().numpy())\n",
        "\n",
        "        if test_auc > best_test_auc:\n",
        "            best_test_auc = test_auc\n",
        "            best_epoch = epoch\n",
        "\n",
        "        print(\"{},{},{},{}\".format(epoch, torch.mean(loss_vector), auc, test_auc))\n",
        "\n",
        "    # print(\"best auc = {} at epoch {}\".format(best_test_auc, best_epoch))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}